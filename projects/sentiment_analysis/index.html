<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sentiment Analysis of Movie Reviews | Navneet Raju </title> <meta name="author" content="Navneet Raju"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://navneetraju.github.io/projects/sentiment_analysis/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Navneet</span> Raju </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Sentiment Analysis of Movie Reviews</h1> <p class="post-description"></p> </header> <article> <h2 id="project-abstract-and-scope">Project Abstract and Scope</h2> <p>The project aims to classify movie reviews as positive or negative us. The reviews are preprocessed and tokenized before being fed into a deep learning model for classification.</p> <h2 id="dataset">Dataset</h2> <p>The Movie Review Data is a collection of movie reviews retrieved from the imdb.com website in the early 2000s by Bo Pang and Lillian Lee. The reviews were collected and made available as part of their research on natural language processing. It consists of 2000 movie reviews, each of which has been tagged as positive or negative. The dataset is available at <a href="https://www.cs.cornell.edu/people/pabo/movie-review-data/" rel="external nofollow noopener" target="_blank">Cornell University</a>.</p> <h2 id="data-exploration-and-pre-processing">Data Exploration and Pre Processing</h2> <h3 id="pre-processing">Pre Processing</h3> <p>We use a standard preprocessing pipeline for text data:</p> <figure class="figure text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/sentiment_analysis/preprocessing-480.webp 480w,/assets/img/projects/sentiment_analysis/preprocessing-800.webp 800w,/assets/img/projects/sentiment_analysis/preprocessing-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/sentiment_analysis/preprocessing.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Preprocessing Pipeline" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figcaption class="figure-caption">Preprocessing Pipeline</figcaption> </figure> <ol> <li>Clean Text: Remove special characters, numbers, and punctuation.</li> <li>Lowercase: Convert all text to lowercase.</li> <li>Stemming: Reduce words to their root form.</li> <li>Stopwords: Remove common words that do not contribute to the meaning of the text.</li> <li>Tokenization: Split the text into words.</li> </ol> <h3 id="dataset-statistics">Dataset statistics</h3> <p>We calculate a few statistics to better understand the dataset:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------- Dataset Statistics ----------------
Feature                                  Value
-----------------------------------    ---------
Total Unique Words                     25297
Average Review Length                  2180.75
Median Review Length                   2024.5
Standard Deviation of Review Length    951.441
-----------------------------------------------------
</code></pre></div></div> <figcaption class="figure-caption text-center">Statistics of the dataset</figcaption> <p><br></p> <div style="text-align: center;"> <figure class="figure text-center" style="max-width: 60%; height: auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/sentiment_analysis/histogram-480.webp 480w,/assets/img/projects/sentiment_analysis/histogram-800.webp 800w,/assets/img/projects/sentiment_analysis/histogram-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/projects/sentiment_analysis/histogram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Review Length Histogram" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figcaption class="figure-caption">Review Length Histogram</figcaption> </figure> </div> <h4 id="tokenization-and-padding">Tokenization and Padding</h4> <p>To represent each text (= data point), there are many ways. In NLP/Deep Learning terminology, this task is called tokenization. It is common to represent text using popularity/ rank of words in text. The most common word in the text will be represented as 1, the second most common word will be represented as 2, etc.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">x_raw</span><span class="p">:</span>
    <span class="n">words</span> <span class="o">+=</span> <span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">()</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="n">sorted_word_counts</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">word_counts</span><span class="p">.</span><span class="nf">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">word_to_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">sorted_word_counts</span><span class="p">,</span> <span class="mi">1</span><span class="p">)}</span>

<span class="k">def</span> <span class="nf">text_to_sequence</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">()</span>
    <span class="n">sequence</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_to_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
</code></pre></div></div> <figcaption class="figure-caption text-center">Rank based tokenization</figcaption> <h4 id="thresholding">Thresholding</h4> <p>Selecting a review length threshold where 70% or 90% of the reviews have a length below it can help manage data preprocessing and analysis in NLP tasks. We choose either 70% or 90% as the threshold.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">L</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">review_lengths</span><span class="p">,</span> <span class="mi">70</span><span class="p">))</span>
</code></pre></div></div> <figcaption class="figure-caption text-center">Thresholding</figcaption> <p>Interpretation</p> <ul> <li>70th Percentile: This means that 70% of the reviews have a length below the value of threshold_70. It helps in focusing on the majority of the reviews without including many outliers.</li> <li>90th Percentile: This means that 90% of the reviews have a length below the value of threshold_90. This is a more inclusive threshold, retaining more reviews but still excluding the longest ones.</li> </ul> <h4 id="word-embeddings">Word Embeddings</h4> <p>One can use tokenized text as inputs to a deep neural network. However, a (not so) recent breakthrough in NLP suggests that more sophisticated representations of text yield better results. These sophisticated representations are called word embeddings. “Word embedding is a term used for representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.”</p> <figure class="figure text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="https://developers.google.com/static/machine-learning/crash-course/images/linear-relationships.svg-480.webp 480w,https://developers.google.com/static/machine-learning/crash-course/images/linear-relationships.svg-800.webp 800w,https://developers.google.com/static/machine-learning/crash-course/images/linear-relationships.svg-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="https://developers.google.com/static/machine-learning/crash-course/images/linear-relationships.svg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Word Embeddings" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figcaption class="figure-caption">Word Embeddings in Vector Space</figcaption> </figure> <p>Most deep learning modules (including PyTorch) provide a convenient way to convert positive integer reresentations of words into a word embedding by an “Embedding layer.” The layer accepts arguments that define the mapping of words into embeddings, including the maximum number of expected words also called the vocabulary size (e.g. the largest integer value). The layer also allows you to specify the dimension for each word vector, called the “embedding dimension.” We would like to use a word embedding layer for this project.</p> <p>Assume that we are interested in the top 5,000 words. This means that in each integer sequence that represents each document, we set to zero those integers that represent words that are not among the top 5,000 words in the document</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
</code></pre></div></div> <figcaption class="figure-caption text-center">Embedding Layer in PyTorch</figcaption> <h2 id="network-architectures">Network Architectures</h2> <p>We experiment with different network architectures to classify the movie reviews.</p> <p><em>Note: We use early stopping in the below implementations to prevent overfitting. Early stopping is a technique used to avoid overfitting when training machine learning models. It works by monitoring the model’s performance on a validation set and stopping training when performance starts to degrade.</em></p> <h3 id="simple-neural-network">Simple Neural Network</h3> <p>We start with a simple neural network with an embedding layer, followed by a fully connected layer and a sigmoid activation function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">16</span>

<span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">NeuralNetwork</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># global average pooling
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc1</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div> <h3 id="lstm">LSTM</h3> <p>We experiment with a Long Short-Term Memory (LSTM) network to classify the movie reviews. LSTM is a type of recurrent neural network that is capable of learning long-term dependencies. It is well-suited to learn from sequences of data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">hidden_dim</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                            <span class="n">dropout</span><span class="o">=</span><span class="n">drop_prob</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Dropout</span><span class="p">(</span><span class="n">drop_prob</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sig</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sigmoid</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">embeds</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span>
        <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">lstm_out</span><span class="p">.</span><span class="nf">contiguous</span><span class="p">().</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">dropout</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">sig_out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sig</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">sig_out</span> <span class="o">=</span> <span class="n">sig_out</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">sig_out</span> <span class="o">=</span> <span class="n">sig_out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="c1"># get last batch of labels
</span>        <span class="k">return</span> <span class="n">sig_out</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">5000</span><span class="o">+</span><span class="mi">1</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">net</span> <span class="o">=</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
</code></pre></div></div> <h3 id="results">Results</h3> <p>We use scikit-learn’s classification report to evaluate the performance of the models.</p> <h4 id="simple-neural-network-1">Simple Neural Network</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       0.87      0.88      0.87       300
           1       0.88      0.86      0.87       300

    accuracy                           0.87       600
   macro avg       0.87      0.87      0.87       600
weighted avg       0.87      0.87      0.87       600
</code></pre></div></div> <p>The simple neural network performs well on the dataset. We can experiment with different hyperparameters and network architectures to improve the performance.</p> <h4 id="lstm-1">LSTM</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       0.00      0.00      0.00       300
           1       0.50      1.00      0.67       300

    accuracy                           0.50       600
   macro avg       0.25      0.50      0.33       600
weighted avg       0.25      0.50      0.33       600
</code></pre></div></div> <p>With the current implementation, the LSTM model does not perform better than the simple neural network. We can experiment with different hyperparameters and network architectures to improve the performance.</p> <h3 id="references">References</h3> <ul> <li>https://en.wikipedia.org/wiki/Word_embedding</li> <li>https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space</li> <li>https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Navneet Raju. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-talks",title:"talks",description:"",section:"Navigation",handler:()=>{window.location.href="/talks/"}},{id:"nav-teaching",title:"teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-tensorflow-dev-summit-2020-tf-quantum",title:"Tensorflow Dev Summit 2020 - TF Quantum",description:"The Tensorflow Dev Summit Livestream which occurred on March 11th revealed some new and exciting tools and platforms. One of the most exciting platforms revelled was Tensorflow Quantum.",section:"Posts",handler:()=>{window.open("https://www.linkedin.com/pulse/tensorflow-dev-summit-2020-tf-quantum-navneet-raju/?trackingId=YQJPDYulR7yxivb6a%2BU25w%3D%3D","_blank")}},{id:"post-using-ai-and-social-media-analytics-to-understand-the-coronavirus-outbreak",title:"Using AI and social media analytics to understand the Coronavirus outbreak.",description:"With the recent outbreak of the novel coronavirus also known as Covid-19 researchers are scrambling to find answers and the vaccine for this virus which has 130k+ cases around the world. But where does technology fight in? With so many advances in technology, there has to seem part of the equation w",section:"Posts",handler:()=>{window.open("https://www.linkedin.com/pulse/using-ai-social-media-analytics-understand-coronavirus-navneet-raju/?trackingId=N%2FwiOFnsRciCe1mhlwVppg%3D%3D","_blank")}},{id:"news-joined-lt-a-href-quot-https-www-gridsusc-com-quot-gt-grids-lt-a-gt-graudates-rising-in-information-and-data-science-at-the-university-of-southern-california-as-an-executive-board-member-for-the-tech-team",title:"Joined &lt;a href=&quot;https://www.gridsusc.com/&quot;&gt;GRIDS&lt;/a&gt; (Graudates Rising in Information and Data Science) at the University of Southern California as an Executive Board Member for the Tech Team.",description:"",section:"News"},{id:"projects-real-time-database-for-flight-data",title:"Real time database for flight data",description:"",section:"Projects",handler:()=>{window.location.href="/projects/airline/"}},{id:"projects-performance-of-different-u-net-architectures-for-inventory-of-coconut-plantations-using-cartosat-2-multispectral-data",title:"Performance of Different U-Net Architectures for Inventory of Coconut Plantations Using Cartosat-2 Multispectral Data",description:"",section:"Projects",handler:()=>{window.location.href="/projects/coconut/"}},{id:"projects-sentiment-analysis-of-movie-reviews",title:"Sentiment Analysis of Movie Reviews",description:"",section:"Projects",handler:()=>{window.location.href="/projects/sentiment_analysis/"}},{id:"projects-signature-forgery-detection-using-siamese-networks",title:"Signature Forgery Detection Using Siamese Networks",description:"",section:"Projects",handler:()=>{window.location.href="/projects/signature_forgery/"}},{id:"projects-vetaql-video-metadata-querying-system-powered-with-video-recommendation",title:"VetaQL: Video Metadata Querying System Powered with Video Recommendation",description:"",section:"Projects",handler:()=>{window.location.href="/projects/vetaql/"}},{id:"projects-vista-video-streaming-and-analytics-benchmark",title:"ViStA: Video Streaming and Analytics Benchmark",description:"",section:"Projects",handler:()=>{window.location.href="/projects/vista/"}},{id:"teaching-pesu-i-o-fundamentals-of-deep-learning",title:"PESU I/O Fundamentals of Deep Learning",description:"",section:"Teaching",handler:()=>{window.location.href="/teaching/io/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%63%6E%61%76%6E%65%65%74%72%61%6A%75@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=MZvhFDsAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/navneetraju","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/navneet-raju-4a07b87b","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>